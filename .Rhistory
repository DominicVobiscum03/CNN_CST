}
x <- torch_cos(frequency(1, N) * sample_positions)
df <- data.frame(x = sample_positions, y = as.numeric(x))
ggplot(df, aes(x = x, y = y)) +
geom_line() +
xlab("time") +
ylab("amplitude") +
theme_minimal()
Ft <- torch_fft_fft(x)
Ft <- torch_fft_fft(x)
real_part <- Ft$real
as.numeric(real_part) %>% round(5)
imag_part <- Ft$imag
as.numeric(imag_part) %>% round(5)
magnitude <- torch_abs(Ft)
as.numeric(magnitude) %>% round(5)
phase <- function(Ft, threshold = 1e5) {
torch_atan2(
torch_abs(torch_round(Ft$imag * threshold)),
torch_abs(torch_round(Ft$real * threshold))
)
}
as.numeric(phase(Ft)) %>% round(5)
create_plot <- function(x, y, quantity) {
df <- data.frame(
x_ = x,
y_ = as.numeric(y) %>% round(5)
)
ggplot(df, aes(x = x_, y = y_)) +
geom_col() +
xlab("frequency") +
ylab(quantity) +
theme_minimal()
}
p_real <- create_plot(
sample_positions,
real_part,
"real part"
)
p_imag <- create_plot(
sample_positions,
imag_part,
"imaginary part"
)
p_magnitude <- create_plot(
sample_positions,
magnitude,
"magnitude"
)
p_phase <- create_plot(
sample_positions,
phase(Ft),
"phase"
)
p_real + p_imag + p_magnitude + p_phase
x <- torch_cos(frequency(4, N) * sample_positions)
plot_ft <- function(x) {
df <- data.frame(x = sample_positions, y = as.numeric(x))
p_signal <- ggplot(df, aes(x = x, y = y)) +
geom_line() +
xlab("time") +
ylab("amplitude") +
theme_minimal()
# in the code, I'm using Ft instead of X because not
# all operating systems treat variables as case-sensitive
Ft <- torch_fft_fft(x)
p_real <- create_plot(
sample_positions,
Ft$real,
"real part"
)
p_imag <- create_plot(
sample_positions,
Ft$imag,
"imaginary part"
)
p_magnitude <- create_plot(
sample_positions,
torch_abs(Ft),
"magnitude"
)
p_phase <- create_plot(
sample_positions,
phase(Ft),
"phase"
)
(p_signal | plot_spacer()) /
(p_real | p_imag) /
(p_magnitude | p_phase)
}
plot_ft(x)
x <- 3 * torch_sin(frequency(4, N) * sample_positions) +
6 * torch_cos(frequency(2, N) * sample_positions) +
2 * torch_cos(frequency(8, N) * sample_positions)
plot_ft(x)
dft <- function(x) {
n_samples <- length(x)
n <- torch_arange(0, n_samples - 1)$unsqueeze(1)
Ft <- torch_complex(
torch_zeros(n_samples), torch_zeros(n_samples)
)
for (k in 0:(n_samples - 1)) {
w_k <- torch_exp(-1i * 2 * pi / n_samples * k * n)
dot <- torch_matmul(w_k, x$to(dtype = torch_cfloat()))
Ft[k + 1] <- dot
}
Ft
}
Ft <- dft(x)
torch_round(Ft$real) %>% as.numeric()
torch_round(Ft$imag) %>% as.numeric()
dft_vec <- function(x) {
n_samples <- length(x)
n <- torch_arange(0, n_samples - 1)$unsqueeze(1)
k <- torch_arange(0, n_samples - 1)$unsqueeze(2)
mat_k_m <- torch_exp(-1i * 2 * pi / n_samples * k * n)
torch_matmul(mat_k_m, x$to(dtype = torch_cfloat()))
}
dft_vec(x)
dft_vec(x)$real
dft_vec <- function(x) {
n_samples <- length(x)
n <- torch_arange(0, n_samples - 1)$unsqueeze(1)
k <- torch_arange(0, n_samples - 1)$unsqueeze(2)
mat_k_m <- torch_exp(-1i * 2 * pi / n_samples * k * n)
torch_matmul(mat_k_m, x$to(dtype = torch_cfloat()))
}
Ft <- dft_vec(x)
torch_round(Ft$real) %>% as.numeric()
torch_round(Ft$imag) %>% as.numeric()
?convolve
m1
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir=normalizePath(".."))
library(neuralnet)
library(tidyverse)
library(binhf)
library(Matrix)
library(ggplot2)
library(pracma)
# read in reference data
m <- read.csv("raw_data/65ref.csv")
m <- m[, -c(1)]
v <- matrix(nrow = 3, ncol = 0)
# Populate 'v' with columns, rows, and values from 'm'
for (i in 1:nrow(m)){
for (j in 1:ncol(m)){
v <- cbind(v, c(i,j,m[i,j]))
}
}
# Create empty vectors `x`, `z`, and 'output'
x <- vector(length = 0)
z <- vector(length = 0)
output <- vector(length = 0)
# Extract values from each row of `v`
for (i in 1:ncol(v)){
x <- c(x, v[2, i])
z <- c(z, v[1, i])
output <- c(output, v[3, i])
}
x <- (x-(max(x)+1)/2) # make x and z correct for the shift flip sum code
z <- (z-(max(z)+1)/2) # origin referenced coordinates
# read in sinogram data
sino <- read.csv('raw_data/65sin.csv')
sino <- sino[, -c(1)]
# number of projections
nAngle  <- ncol(sino)
# number of detectors
nDetect <- nrow(sino)
# Degrees between projections
angleStep <- 180/(nAngle-1)
# compute angle of each projection in sinogram
degree <- data.frame(angle = seq(0,nAngle-1)*angleStep)
# initialize weights
nn <- list()
nn$weights <- list()
nn$weights[[1]] <- matrix(0, nrow = 91, ncol = 2)
nn$weights[[2]] <- matrix(0, nrow = 3, ncol = 1)
error <- matrix(nrow = 1, ncol = 0)
for (i in 1:length(output)){
# compute shift of sinogram detector positions for each projection based on current image pixel
degree$pixel <- round(x[i]*cos(pi*degree$angle/180) + z[i]*sin(pi*degree$angle/180))
# transpose the sinogram
tsino <- t(sino)
# create a space with dimension tsino
ssino <- tsino
######################################################## SHIFT SUM FLIP
# Perform shift according to dShift
for (j in 1:nAngle){
shift_amount <- degree$pixel[j]
shifted_row <- circshift(tsino[j, ], shift_amount)
ssino[j, ] <- shifted_row
}
# perform summation
f_vector <- colSums(ssino)
# perform flip
z_vector <- rev(f_vector)
################################################################## DATA
data <- t(as_tibble(c(z_vector, output[i])))
# Define names of the columns for the data to used by function
ANN_names <- c(paste0("z",(as.character(c(seq(1:nDetect))))),"o")
colnames(data) <- ANN_names
############################################################### FORMULA
f <- as.formula(paste(ANN_names[nDetect+1],
"~",
paste(ANN_names[!ANN_names %in% "o"], collapse = " + ")
)
)
############################################################ NEURAL NET
nn <-neuralnet(f, data, hidden = 2,
startweights = nn$weights,
algorithm = 'backprop',
learningrate = 0.0001)
error[i] <- nn$result.matrix[1]
}
plot(nn, rep = "best")
# Creating matrices 'm1' which contains the weights from the first layer and 'm2' which contains the
# weights from the second layer
m1 <- nn$weights[[1]][[1]]
m2 <- nn$weights[[1]][[2]]
m1 <- m1 %>% as.data.frame()
m2 <- m2 %>% as.data.frame()
# read in sinogram data
sino <- read.csv('raw_data/65sin.csv')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir=normalizePath(".."))
library(neuralnet)
library(tidyverse)
library(binhf)
library(Matrix)
library(ggplot2)
library(pracma)
# read in reference data
m <- read.csv("raw_data/65ref.csv")
m <- m[, -c(1)]
v <- matrix(nrow = 3, ncol = 0)
# Populate 'v' with columns, rows, and values from 'm'
for (i in 1:nrow(m)){
for (j in 1:ncol(m)){
v <- cbind(v, c(i,j,m[i,j]))
}
}
# Create empty vectors `x`, `z`, and 'output'
x <- vector(length = 0)
z <- vector(length = 0)
output <- vector(length = 0)
# Extract values from each row of `v`
for (i in 1:ncol(v)){
x <- c(x, v[2, i])
z <- c(z, v[1, i])
output <- c(output, v[3, i])
}
x <- (x-(max(x)+1)/2) # make x and z correct for the shift flip sum code
z <- (z-(max(z)+1)/2) # origin referenced coordinates
# read in sinogram data
sino <- read.csv('raw_data/65sin.csv')
sino <- sino[, -c(1)]
# number of projections
nAngle  <- ncol(sino)
# number of detectors
nDetect <- nrow(sino)
# Degrees between projections
angleStep <- 180/(nAngle-1)
# compute angle of each projection in sinogram
degree <- data.frame(angle = seq(0,nAngle-1)*angleStep)
# initialize weights
nn <- list()
nn$weights <- list()
nn$weights[[1]] <- matrix(0, nrow = 16, ncol = 2)
nn$weights[[2]] <- matrix(0, nrow = 3, ncol = 1)
error <- matrix(nrow = 1, ncol = 0)
for (i in 1:length(output)){
# compute shift of sinogram detector positions for each projection based on current image pixel
degree$pixel <- round(x[i]*cos(pi*degree$angle/180) + z[i]*sin(pi*degree$angle/180))
# transpose the sinogram
tsino <- t(sino)
# create a space with dimension tsino
ssino <- tsino
######################################################## SHIFT SUM FLIP
# Perform shift according to dShift
for (j in 1:nAngle){
shift_amount <- degree$pixel[j]
shifted_row <- circshift(tsino[j, ], shift_amount)
ssino[j, ] <- shifted_row
}
# perform summation
f_vector <- colSums(ssino)
# perform flip
z_vector <- rev(f_vector)
################################################################## DATA
data <- t(as_tibble(c(z_vector, output[i])))
# Define names of the columns for the data to used by function
ANN_names <- c(paste0("z",(as.character(c(seq(1:nDetect))))),"o")
colnames(data) <- ANN_names
############################################################### FORMULA
f <- as.formula(paste(ANN_names[nDetect+1],
"~",
paste(ANN_names[!ANN_names %in% "o"], collapse = " + ")
)
)
############################################################ NEURAL NET
nn <-neuralnet(f, data, hidden = 2,
startweights = nn$weights,
algorithm = 'backprop',
learningrate = 0.0001)
error[i] <- nn$result.matrix[1]
}
plot(nn, rep = "best")
# Creating matrices 'm1' which contains the weights from the first layer and 'm2' which contains the
# weights from the second layer
m1 <- nn$weights[[1]][[1]]
m2 <- nn$weights[[1]][[2]]
m1 <- m1 %>% as.data.frame()
m2 <- m2 %>% as.data.frame()
filt_sinoA <- sino
filt_sinoB <- sino
number_cols <- ncol(sino)
#for(val in 1:number_cols){
#filt_sinoA[,val] <- convolve(sino[,val], m1[2:91,1], type ="circular")
#}
#filt_sinoA %>%
# as.matrix()
#write_csv(filt_sinoA, "raw_data/filtsinoa.csv")
#for(val in 1:number_cols){
# filt_sinoB[,val] <- convolve(sino[,val], m1[2:91,2], type ="circular")
#}
#filt_sinoB %>%
#as.matrix()
#write_csv(filt_sinoB, "raw_data/filtsinob.csv")
filt1 <- convolution(sino, m1[2:91,1], 'same')
install.packages("OpenImageR")
library(OpenImageR)
filt_sinoA <- sino
filt_sinoB <- sino
number_cols <- ncol(sino)
#for(val in 1:number_cols){
#filt_sinoA[,val] <- convolve(sino[,val], m1[2:91,1], type ="circular")
#}
#filt_sinoA %>%
# as.matrix()
#write_csv(filt_sinoA, "raw_data/filtsinoa.csv")
#for(val in 1:number_cols){
# filt_sinoB[,val] <- convolve(sino[,val], m1[2:91,2], type ="circular")
#}
#filt_sinoB %>%
#as.matrix()
#write_csv(filt_sinoB, "raw_data/filtsinob.csv")
filt1 <- convolution(sino, m1[2:91,1], 'same')
m1 <- m1 %>% as.matrix()
m2 <- m2 %>% as.matrix()
filt1 <- convolution(sino, m1[2:91,1], 'same')
filt2 <- convolution(sino, m2[2:91,1], 'same')
filt2 <- convolution(sino, m2[2:91,2], 'same')
m2
filt2 <- convolution(sino, m1[2:91,2], 'same')
m1
type(m1)
filt_sinoA <- sino
filt_sinoB <- sino
number_cols <- ncol(sino)
#for(val in 1:number_cols){
#filt_sinoA[,val] <- convolve(sino[,val], m1[2:91,1], type ="circular")
#}
#filt_sinoA %>%
# as.matrix()
#write_csv(filt_sinoA, "raw_data/filtsinoa.csv")
#for(val in 1:number_cols){
# filt_sinoB[,val] <- convolve(sino[,val], m1[2:91,2], type ="circular")
#}
#filt_sinoB %>%
#as.matrix()
#write_csv(filt_sinoB, "raw_data/filtsinob.csv")
m1 <- m1 %>% as.matrix()
m2 <- m2 %>% as.matrix()
filt1 <- convolution(sino, m1[2:91,1], 'same')
filt1 <- convolution(sino, m1[1:91,1], 'same')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
library(tidymodels)
library(torch)
library(torchaudio)
library(torchvision)
library(luz)
# input dimensionality (number of input features)
d_in <- 3
# number of observations in training set
n <- 100
x <- torch_randn(n, d_in)
coefs <- c(0.2, -1.3, -0.5)
y <- x$matmul(coefs)$unsqueeze(2) + torch_randn(n, 1)
x
coegs
coefs
y
# dimensionality of hidden layer
d_hidden <- 32
# output dimensionality (number of predicted features)
d_out <- 1
net <- nn_sequential(
nn_linear(d_in, d_hidden),
nn_relu(),
nn_linear(d_hidden, d_out)
)
opt <- optim_adam(net$parameters)
### training loop --------------------------------------
for (t in 1:200) {
### -------- Forward pass --------
y_pred <- net(x)
### -------- Compute loss --------
loss <- nnf_mse_loss(y_pred, y)
if (t %% 10 == 0)
cat("Epoch: ", t, "   Loss: ", loss$item(), "\n")
### -------- Backpropagation --------
opt$zero_grad()
loss$backward()
### -------- Update weights --------
opt$step()
}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
library(tidymodels)
library(torch)
library(torchaudio)
library(torchvision)
library(luz)
# input dimensionality (number of input features)
d_in <- 3
# number of observations in training set
n <- 100
x <- torch_randn(n, d_in)
coefs <- c(0.2, -1.3, -0.5)
y <- x$matmul(coefs)$unsqueeze(2) + torch_randn(n, 1)
# dimensionality of hidden layer
d_hidden <- 32
# output dimensionality (number of predicted features)
d_out <- 1
net <- nn_sequential(
nn_linear(d_in, d_hidden),
nn_relu(),
nn_linear(d_hidden, d_out)
)
opt <- optim_adam(net$parameters)
### training loop --------------------------------------
for (t in 1:2000) {
### -------- Forward pass --------
y_pred <- net(x)
### -------- Compute loss --------
loss <- nnf_mse_loss(y_pred, y)
if (t %% 10 == 0)
cat("Epoch: ", t, "   Loss: ", loss$item(), "\n")
### -------- Backpropagation --------
opt$zero_grad()
loss$backward()
### -------- Update weights --------
opt$step()
}
opt <- optim_adam(net$parameters)
### training loop --------------------------------------
for (t in 1:20000) {
### -------- Forward pass --------
y_pred <- net(x)
### -------- Compute loss --------
loss <- nnf_mse_loss(y_pred, y)
if (t %% 10 == 0)
cat("Epoch: ", t, "   Loss: ", loss$item(), "\n")
### -------- Backpropagation --------
opt$zero_grad()
loss$backward()
### -------- Update weights --------
opt$step()
}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
library(tidymodels)
library(torch)
library(torchaudio)
library(torchvision)
library(luz)
# input dimensionality (number of input features)
d_in <- 3
# number of observations in training set
n <- 100
x <- torch_randn(n, d_in)
coefs <- c(0.2, -1.3, -0.5)
y <- x$matmul(coefs)$unsqueeze(2) + torch_randn(n, 1)
# dimensionality of hidden layer
d_hidden <- 32
# output dimensionality (number of predicted features)
d_out <- 1
net <- nn_sequential(
nn_linear(d_in, d_hidden),
nn_relu(),
nn_linear(d_hidden, d_out)
)
opt <- optim_adam(net$parameters)
### training loop --------------------------------------
for (t in 1:20000) {
### -------- Forward pass --------
y_pred <- net(x)
### -------- Compute loss --------
loss <- nnf_mse_loss(y_pred, y)
if (t %% 10 == 0)
cat("Epoch: ", t, "   Loss: ", loss$item(), "\n")
### -------- Backpropagation --------
opt$zero_grad()
loss$backward()
### -------- Update weights --------
opt$step()
}
knitr::opts_knit$set(root.dir = normalizePath(".."))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))
